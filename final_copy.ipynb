{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import json\n",
    "from pathlib import Path as Data_Path\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.11.0; Torch-cuda version: None; Torch Geometric version: 2.1.0.\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.nn import Embedding, ModuleList, Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch.nn.modules.loss import _Loss\n",
    "\n",
    "from torch_geometric.nn.conv import LGConv, GATConv, SAGEConv\n",
    "from torch_geometric.typing import Adj, OptTensor, SparseTensor\n",
    "\n",
    "\n",
    "print(f\"Torch version: {torch.__version__}; Torch-cuda version: {torch.version.cuda}; Torch Geometric version: {torch_geometric.__version__}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed for reproducibility\n",
    "seed = 224\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Defining classes\n",
    "\n",
    "class Product:\n",
    "  def __init__(self, title, asin, description, also_bought, categories):\n",
    "    self.title = title #name, string\n",
    "    self.asin = asin #string\n",
    "    self.description = description #string\n",
    "    # self.features = features # String[]\n",
    "    self.also_bought = also_bought #asin[]\n",
    "    if categories is None:\n",
    "      self.categories = set()\n",
    "    self.categories = set(categories) #categories[]\n",
    "\n",
    "\n",
    "  def __str__(self):\n",
    "    return f\"Product {self.title}\"\n",
    "\n",
    "class Category:\n",
    "  def __init__(self, name):\n",
    "    self.name = name\n",
    "    self.products = []\n",
    "\n",
    "  def add_to_category(self, product):\n",
    "    self.products.append(product)\n",
    "\n",
    "  def __str__(self):\n",
    "    return f\"Category {self.name} has {len(self.products)} in it.\"\n",
    "\n",
    "class User:\n",
    "  def __init__(self, reviewerID):\n",
    "    self.reviewerID = reviewerID\n",
    "    self.products_reviewed = []\n",
    "    #maybe we can add the categories that they reviewed?\n",
    "\n",
    "  def add_to_reviewed(self, product):\n",
    "    self.products_reviewed.append(product)\n",
    "\n",
    "  def __str__(self):\n",
    "    return f\"User {self.reviewerID} has reviewed {len(self.products_reviewed)} products\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# reviews = pd.read_csv(\"Gift_Cards.csv\")\n",
    "review_data = []\n",
    "review_name = 'Gift_Cards_5.json'\n",
    "with open(review_name, 'r') as file:\n",
    "    for line in file:\n",
    "      review_data.append(json.loads(line))\n",
    "file_metadata = []\n",
    "metadata_link = \"meta_Gift_Cards.json\"\n",
    "with open(metadata_link, 'r') as file:\n",
    "    for line in file:\n",
    "      file_metadata.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(categories_names)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "# print(onehot_encoded)\n",
    "\n",
    "def vec_to_category(vector) -> str:\n",
    "    return label_encoder.inverse_transform([np.argmax(vector)])[0]\n",
    "\n",
    "def categories_to_vec(categories):\n",
    "    categories = list(set(categories))\n",
    "    integer_encoded = label_encoder.transform(categories)\n",
    "    integer_encoded = integer_encoded.reshape(-1, 1)\n",
    "    onehot_encoded = onehot_encoder.transform(integer_encoded)\n",
    "    # print(onehot_encoded)\n",
    "    output = onehot_encoded[0]\n",
    "    for i in range(1, len(onehot_encoded)):\n",
    "        output += onehot_encoded[i]\n",
    "    return output\n",
    "\n",
    "print(categories_to_vec(['Gift Cards', 'Gift Card Accessories']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = {}\n",
    "all_categories = {}\n",
    "users = {}\n",
    "\n",
    "def process_review_data(review):\n",
    "  try:\n",
    "    userID = review['reviewerID']\n",
    "  except:\n",
    "    print(review)\n",
    "  if userID not in users:\n",
    "    new_user = User(userID)\n",
    "    users[userID] = new_user\n",
    "  rating = int(review['overall'])\n",
    "  users[userID].add_to_reviewed((review['asin'], rating))\n",
    "\n",
    "def process_metadata(metadata):\n",
    "  asin = metadata['asin']\n",
    "  # features = metadata['features']\n",
    "  also_bought = metadata['also_buy']\n",
    "  description = metadata['description']\n",
    "  categories = metadata['category']\n",
    "  title = metadata['title']\n",
    "  if asin not in products:\n",
    "    new_product = Product(title, asin, description, also_bought, categories)\n",
    "    products[asin] = new_product\n",
    "  # for category in categories:\n",
    "  #   if category not in all_categories:\n",
    "  #     all_categories[category] = Category(category)\n",
    "  #   all_categories[category].add_to_category(asin)\n",
    "\n",
    "\n",
    "def load_data():\n",
    "  for line in review_data:\n",
    "    process_review_data(line)\n",
    "  for line in file_metadata:\n",
    "    process_metadata(line)\n",
    "\n",
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gift Cards': <__main__.Category at 0x7fe71cf56070>,\n",
       " 'Gift Card Accessories': <__main__.Category at 0x7fe71cf563d0>,\n",
       " '</span></span></span>': <__main__.Category at 0x7fe71cf56490>,\n",
       " 'No expiration, no fees.': <__main__.Category at 0x7fe71cf93130>,\n",
       " 'Redeemable toward millions of items storewide on Amazon.com.': <__main__.Category at 0x7fe71cf93190>,\n",
       " 'Multiple denominations. Choose your amount from $1.00 to $2,000.': <__main__.Category at 0x7fe71cf931f0>,\n",
       " 'Variety of designs for any occasion.': <__main__.Category at 0x7fe71cf93250>,\n",
       " 'Made with thick, 100% recycled paper stock, sealed with vinyl laminate and hand sewn with clear vinyl pockets': <__main__.Category at 0x7fe71cff0910>,\n",
       " \"Holds Credit Cards, Business Cards, ID's and or Bus & Train Passes\": <__main__.Category at 0x7fe71cff0970>,\n",
       " 'Great for \"going out\" or by the pool when just the essentials are needed': <__main__.Category at 0x7fe71cff09d0>,\n",
       " 'Unique, eye-catching designs which rival boring, plain card cases': <__main__.Category at 0x7fe71cff0a30>,\n",
       " 'Handmade with recycled materials in Los Angeles': <__main__.Category at 0x7fe71cff0a90>,\n",
       " 'Starbucks Gift Card 25': <__main__.Category at 0x7fe71d0147f0>,\n",
       " 'Starbucks': <__main__.Category at 0x7fe71d014850>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Create instances of your classes\n",
    "# This is just a placeholder. Replace this with your actual data.\n",
    "# products = [...]\n",
    "# categories = [...]\n",
    "# users = [...]\n",
    "\n",
    "# Create mappings from unique IDs to consecutive integers\n",
    "unique_user_id = [user for user in users]\n",
    "unique_user_id = pd.DataFrame(data={\n",
    "   'userId': unique_user_id,\n",
    "   'mappedID': pd.RangeIndex(len(unique_user_id)),\n",
    "})\n",
    "\n",
    "unique_product_id = [product for product in products]\n",
    "unique_product_id = pd.DataFrame(data={\n",
    "   'productId': unique_product_id,\n",
    "   'mappedID': pd.RangeIndex(len(unique_product_id)),\n",
    "})\n",
    "\n",
    "# unique_category_id = [category for category in all_categories]\n",
    "# unique_category_id = pd.DataFrame(data={\n",
    "#    'categoryId': unique_category_id,\n",
    "#    'mappedID': pd.RangeIndex(len(unique_category_id)),\n",
    "# })\n",
    "# print(unique_user_id)\n",
    "# Construct the edge indices\n",
    "# User to Product (Review)\n",
    "user_product_edges = []\n",
    "user_product_ratings = []\n",
    "for user_name in users:\n",
    "   user_object = users[user_name]\n",
    "   for product_id, rating in users[user_name].products_reviewed:\n",
    "      product = products[product_id]\n",
    "      user_product_edges.append([unique_user_id.loc[unique_user_id['userId'] == user_object.reviewerID, 'mappedID'].values[0],\n",
    "                              unique_product_id.loc[unique_product_id['productId'] == product.asin, 'mappedID'].values[0]])\n",
    "      user_product_ratings.append(rating)\n",
    "user_product_edges = torch.t(torch.tensor(user_product_edges, dtype=torch.long))\n",
    "user_product_ratings = torch.tensor(user_product_ratings, dtype=torch.float) \n",
    "# user_product_ratings = torch.reshape(user_product_ratings, (1, len(user_product_ratings)))\n",
    "\n",
    "print(user_product_edges.shape)\n",
    "\n",
    "# Product to Product (Also Bought)\n",
    "product_product_edges = []\n",
    "for product_id in products:\n",
    "   product = products[product_id]\n",
    "   for also_bought_product in products[product_id].also_bought:\n",
    "      #  print(also_bought_product)\n",
    " \n",
    "       if (unique_product_id['productId'] == also_bought_product).any():  \n",
    "         product_product_edges.append([unique_product_id.loc[unique_product_id['productId'] == product.asin, 'mappedID'].values[0],\n",
    "                                   unique_product_id.loc[unique_product_id['productId'] == also_bought_product, 'mappedID'].values[0]])\n",
    "# print(len(product_product_edges))\n",
    "product_product_edges = torch.t(torch.tensor(product_product_edges, dtype=torch.long))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class TextEncoder:\n",
    "    \"\"\"\n",
    "    A class for encoding text using a SentenceTransformer model.\n",
    "    \"\"\"\n",
    "    def __init__(self, model='all-MiniLM-L6-v2', device=None):\n",
    "        \"\"\"\n",
    "        :param model: Name of the SentenceTransformer model to use.\n",
    "        :param device: Device to use for model inference. Default is None.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.model = SentenceTransformer(model, device=self.device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, values: list):\n",
    "        \"\"\"\n",
    "        Encode a list of text values into embeddings.\n",
    "\n",
    "        :param values: List of text values to encode.\n",
    "        :return: Encoded embeddings as a PyTorch tensor.\n",
    "        \"\"\"\n",
    "        x = self.model.encode(values,\n",
    "                              show_progress_bar=True,\n",
    "                              convert_to_tensor=True,\n",
    "                              device=self.device)\n",
    "        return x.cpu()\n",
    "\n",
    "\n",
    "# Check if CUDA is available, and set the device accordingly\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# Create an instance of the TextEncoder class with the determined device\n",
    "encoder = TextEncoder(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create product features\n",
    "dummy = torch.zeros((1, 200))\n",
    "\n",
    "product_features = torch.zeros((len(unique_product_id), 384+dummy.shape[1]))\n",
    "for product_id in products:\n",
    "    product = products[product_id]\n",
    "    mapped_id = unique_product_id.loc[unique_product_id['productId'] == product.asin, 'mappedID'].values[0]\n",
    "    d = \"\"\n",
    "    for descrip in product.description:\n",
    "        d = d + descrip\n",
    "    product.description = d\n",
    "    if product.description == \"\":\n",
    "        product_features[mapped_id] = torch.cat((encoder(\"None\"), dummy), 1)\n",
    "    else:\n",
    "        product_features[mapped_id] = torch.cat((encoder(product.description), dummy), 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "data = HeteroData()\n",
    "\n",
    "# Add node features to the HeteroData object\n",
    "data['Product'].x = product_features\n",
    "# data['User'].x = torch.ones(len(users), 1)\n",
    "data['User'].x = torch.eye(len(users))\n",
    "\n",
    "# Add edge indices to the HeteroData object\n",
    "data['User', 'REVIEWS', 'Product'].edge_index = user_product_edges\n",
    "data['User', 'REVIEWS', 'Product'].edge_label = user_product_ratings\n",
    "data['Product', 'ALSO_BOUGHT', 'Product'].edge_index = product_product_edges\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "data = T.ToUndirected()(data)\n",
    "\n",
    "del data['Product', 'rev_REVIEWS', 'User'].edge_label\n",
    "del data['Product', 'rev_ALSO_BOUGHT', 'Product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[('User', 'REVIEWS', 'Product'), ('Product', 'ALSO_BOUGHT', 'Product')],\n",
    "    rev_edge_types=[('Product', 'rev_REVIEWS', 'User')],\n",
    ")(data)\n",
    "train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = torch.nn.Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = torch.nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_dict['User'][row], z_dict['Product'][col]], dim=-1)\n",
    "\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Model(hidden_channels=32).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
    "                 train_data['User', 'Product'].edge_label_index)\n",
    "    target = train_data['User', 'Product'].edge_label\n",
    "    loss = F.mse_loss(pred, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    data = data.to(device)\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict,\n",
    "                 data['User', 'Product'].edge_label_index)\n",
    "    pred = pred.clamp(min=0, max=5)\n",
    "    target = data['User', 'Product'].edge_label.float()\n",
    "    rmse = F.mse_loss(pred, target).sqrt()\n",
    "    return float(rmse)\n",
    "\n",
    "\n",
    "for epoch in range(1, 301):\n",
    "    train_data = train_data.to(device)\n",
    "    loss = train()\n",
    "    train_rmse = test(train_data)\n",
    "    val_rmse = test(val_data)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
    "          f'Val: {val_rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_data = test_data.to(device)\n",
    "    pred = model(test_data.x_dict, test_data.edge_index_dict,\n",
    "                 test_data['user', 'movie'].edge_label_index)\n",
    "    pred = pred.clamp(min=0, max=5)\n",
    "    target = test_data['user', 'movie'].edge_label.float()\n",
    "    rmse = F.mse_loss(pred, target).sqrt()\n",
    "    print(f'Test RMSE: {rmse:.4f}')\n",
    "\n",
    "userId = test_data['user', 'movie'].edge_label_index[0].cpu().numpy()\n",
    "movieId = test_data['user', 'movie'].edge_label_index[1].cpu().numpy()\n",
    "pred = pred.cpu().numpy()\n",
    "target = target.cpu().numpy()\n",
    "\n",
    "print(pd.DataFrame({'userId': userId, 'movieId': movieId, 'rating': pred, 'target': target}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
